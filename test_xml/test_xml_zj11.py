#coding=utf-8
#__author__ = 'lg 2018-8-9'

import copy
import cv2
import os
import xml.dom
import xml.dom.minidom
import numpy as np
import time
from caffe2.python import workspace
from core.config import merge_cfg_from_file
import core.test_engine as infer_engine
import datasets.dummy_datasets as dummy_datasets
import utils.c2 as c2_utils
import core.test_engine as infer_engine
c2_utils.import_detectron_ops()
# OpenCL may be enabled by default in OpenCV3; disable it because it's not
# thread safe and causes unwanted GPU memory allocations.
cv2.ocl.setUseOpenCL(False)


WRITE_XML = False
PLOT      = True
PRINT = False    #True

class Model():
    
    def __init__(self,cfg_path,weights_path):
    
        #nms_same_class 0.3  ----  *.yaml/TEST:NMS:0.3 中设置 defalut 0.5
        
        self.gpu_id = 0               #gpu_id default 0
        
        self.score_thresh = 0.3       #score > score_thresh  default 0.3  
        
        self.per_class_thresh = False         #score > class_score_thresh
        self.autotruck_score_thresh = 0.6
        self.forklift_score_thresh = 0.65
        self.digger_score_thresh = 0.65
        self.car_score_thresh = 0.45
        self.bus_score_thresh = 0.0
        self.tanker_score_thresh = 0.55
        self.person_score_thresh = 0.35
        self.minitruck_score_thresh = 0.0
        self.minibus_score_thresh = 0.59
        
        self.class_nms_thresh = 0.85   #nms_between_classes  IOU > class_nms_thresh    default 0.9 
        merge_cfg_from_file(cfg_path)
        self.model = infer_engine.initialize_model_from_cfg(weights_path,self.gpu_id)
        self.dummy_coco_dataset = dummy_datasets.get_steal_oil_class14_dataset()
        print ("model is ok")

    def predict(self,im):

        #class_str_list = []
        data_list = []
        
        with c2_utils.NamedCudaScope(self.gpu_id):
            cls_boxes, cls_segms, cls_keyps = infer_engine.im_detect_all(self.model, im, None, None
            )
            
        #get box classes
        if isinstance(cls_boxes, list):
            boxes, segms, keypoints, classes = self.convert_from_cls_format(cls_boxes, cls_segms, cls_keyps)
        if boxes is None or boxes.shape[0] == 0 or max(boxes[:, 4]) < self.score_thresh:
            return data_list
        #get score
        areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])
        sorted_inds = np.argsort(-areas)
        
        #nms between classes
        #im2 = cv2.cvtColor(im,cv2.COLOR_RGB2BGR)
        #result2= im2.copy()        
        if (len(sorted_inds) > 0):        
            nmsIndex = self.nms_between_classes(boxes, self.class_nms_thresh)  #阈值为0.9，阈值越大，过滤的越少 
            for i in xrange(len(nmsIndex)):                
                bbox = boxes[nmsIndex[i], :4]
                score = boxes[nmsIndex[i], -1]
                if score < self.score_thresh:
                    continue
                #get class-str
                class_str = self.get_class_string(classes[nmsIndex[i]], score, self.dummy_coco_dataset)
                
                #score thresd per class
                if self.per_class_thresh:
                    if 'autotruck' == class_str and score < self.autotruck_score_thresh:
                        continue
                    if 'forklift'  == class_str and score < self.forklift_score_thresh:
                        continue
                    if 'digger'    == class_str and score < self.digger_score_thresh:
                        continue
                    if 'car'       == class_str and score < self.car_score_thresh:
                        continue
                    if 'bus'       == class_str and score < self.bus_score_thresh:
                        continue
                    if 'tanker'    == class_str and score < self.tanker_score_thresh:
                        continue
                    if 'person'    == class_str and score < self.person_score_thresh:
                        continue
                    if 'minitruck' == class_str and score < self.minitruck_score_thresh:
                        continue
                    if 'minibus'   == class_str and score < self.minibus_score_thresh:
                        continue
                
                single_data = {"cls":class_str,"score":float('%.2f' % score),"bbox":{"xmin":int(bbox[0]),"ymin":int(bbox[1]),"xmax":int(bbox[2]),"ymax":int(bbox[3])}}
                data_list.append(single_data)        
        
        #construcrion - data_list
        return data_list
        
    def convert_from_cls_format(self,cls_boxes, cls_segms, cls_keyps):
        """Convert from the class boxes/segms/keyps format generated by the testing
        code.
        """
        box_list = [b for b in cls_boxes if len(b) > 0]
        if len(box_list) > 0:
            boxes = np.concatenate(box_list)
        else:
            boxes = None
        if cls_segms is not None:
            segms = [s for slist in cls_segms for s in slist]
        else:
            segms = None
        if cls_keyps is not None:
            keyps = [k for klist in cls_keyps for k in klist]
        else:
            keyps = None
        classes = []
        for j in range(len(cls_boxes)):
            classes += [j] * len(cls_boxes[j])
        return boxes, segms, keyps, classes
        
    def get_class_string(self,class_index, score, dataset):
        class_text = dataset.classes[class_index] if dataset is not None else \
            'id{:d}'.format(class_index)
        #return class_text + ' {:0.2f}'.format(score).lstrip('0')
        return class_text
    def nms_between_classes(self,boxes, threshold):
        if boxes.size==0:
            return np.empty((0,3))
        x1 = boxes[:,0]
        y1 = boxes[:,1]
        x2 = boxes[:,2]
        y2 = boxes[:,3]
        s = boxes[:,4]
        area = (x2-x1+1) * (y2-y1+1)
        I = np.argsort(s)
        pick = np.zeros_like(s, dtype=np.int16)
        counter = 0
        while I.size>0:
            i = I[-1]
            pick[counter] = i
            counter += 1
            idx = I[0:-1]
            xx1 = np.maximum(x1[i], x1[idx])
            yy1 = np.maximum(y1[i], y1[idx])
            xx2 = np.minimum(x2[i], x2[idx])
            yy2 = np.minimum(y2[i], y2[idx])
            w = np.maximum(0.0, xx2-xx1+1)
            h = np.maximum(0.0, yy2-yy1+1)
            inter = w * h        
            o = inter / (area[i] + area[idx] - inter)
            I = I[np.where(o<=threshold)]
        pick = pick[0:counter]  #返回nms后的索引
        return pick

class Xml():
    def __init__(self):
        self.INDENT= ' '*4
        self.NEW_LINE= '\n'
        self.FOLDER_NODE= 'VOC2010'
        self.ROOT_NODE= 'annotation'
        self.DATABASE_NAME= 'VOC2010'
        self.ANNOTATION= 'PASCALVOC2010'
        self.AUTHOR= 'HHJ'
        self.SEGMENTED= '0'
        self.DIFFICULT= '0'
        self.TRUNCATED= '0'
        self.OCCLUDED = '0'
        self.POSE= 'Unspecified'

    def xml(self,outpath,outname,predict_datalist,img_size):
        my_dom = xml.dom.getDOMImplementation()
        doc = my_dom.createDocument(None,self.ROOT_NODE,None)
        # 获得根节�?
        root_node = doc.documentElement
        # folder节点
        self.createChildNode(doc, 'folder',self.FOLDER_NODE, root_node)
        # filename节点
        self.createChildNode(doc, 'filename', outname.rsplit('.', 1)[0]+'.jpg',root_node)
        # source节点
        source_node = doc.createElement('source')
        # source的子节点
        self.createChildNode(doc, 'database',self.DATABASE_NAME, source_node)
        self.createChildNode(doc, 'annotation',self.ANNOTATION, source_node)
        self.createChildNode(doc, 'image','flickr', source_node)
        self.createChildNode(doc, 'flickrid','NULL', source_node)
        root_node.appendChild(source_node)
        # owner节点
        owner_node = doc.createElement('owner')
        # owner的子节点
        self.createChildNode(doc, 'flickrid','NULL', owner_node)
        self.createChildNode(doc, 'name',self.AUTHOR, owner_node)
        root_node.appendChild(owner_node)
        # size节点
        size_node = doc.createElement('size')
        self.createChildNode(doc, 'width',str(img_size[1]), size_node)
        self.createChildNode(doc, 'height',str(img_size[0]), size_node)
        self.createChildNode(doc, 'depth',str(img_size[2]), size_node)
        root_node.appendChild(size_node)
        # segmented节点
        self.createChildNode(doc, 'segmented',self.SEGMENTED, root_node)
        #添加图片的 类别
        for j in xrange(len(predict_datalist)):
            singledata = predict_datalist[j]
            object_node = self.createObjectNode(doc, singledata)
            root_node.appendChild(object_node)
        # # 写入文件
        #
        self.writeXMLFile(doc,outpath,outname)
            
    def createElementNode(self,doc,tag, attr):  # 创建一个元素节点
        element_node = doc.createElement(tag)
        # 创建一个文本节点
        text_node = doc.createTextNode(attr)
        # 将文本节点作为元素节点的子节点
        element_node.appendChild(text_node)
        return element_node

# 封装添加一个子节点的过
    def createChildNode(self,doc,tag, attr,parent_node):
        child_node = self.createElementNode(doc, tag, attr)
        parent_node.appendChild(child_node)

    # object节点比较特殊
    def createObjectNode(self,doc,attrs):
        object_node = doc.createElement('object')
        self.createChildNode(doc, 'name', attrs['cls'],object_node)
        self.createChildNode(doc, 'pose',self.POSE, object_node)
        self.createChildNode(doc, 'truncated',self.TRUNCATED, object_node)
        self.createChildNode(doc, 'difficult',self.DIFFICULT, object_node)
        self.createChildNode(doc, 'occluded',self.OCCLUDED, object_node)
        bndbox_node = doc.createElement('bndbox')
        self.createChildNode(doc, 'xmin', str(int(attrs['bbox']['xmin'])),bndbox_node)
        self.createChildNode(doc, 'ymin', str(int(attrs['bbox']['ymin'])),bndbox_node)
        self.createChildNode(doc, 'xmax', str(int(attrs['bbox']['xmax'])),bndbox_node)
        self.createChildNode(doc, 'ymax', str(int(attrs['bbox']['ymax'])),bndbox_node)
        object_node.appendChild(bndbox_node)
        return object_node

    # 将documentElement写入XML文件�?
    def writeXMLFile(self,doc,outpath,filename):
        tmpfile =open(os.path.join(outpath,filename),'w')
        doc.writexml(tmpfile, addindent=self.INDENT,newl = '\n',encoding = 'utf-8')
        tmpfile.close()

#predict and filter area
def singlePredict(mm,imgPath, output_xmlpath,num_no_target, maxArea):
    score_lst=[]
    xmin_lst=[]
    xmax_lst=[]
    ymin_lst=[]
    ymax_lst=[]
    if not os.path.exists(imgPath):
        print ('{} is not exist!!!'.format(imgPath))
        return None,score_lst,xmin_lst,ymin_lst,xmax_lst,ymax_lst,num_no_target
        
    img_np = cv2.imread(imgPath)
    if img_np is None:
        return None,score_lst,xmin_lst,ymin_lst,xmax_lst,ymax_lst,num_no_target
        
    img_size = img_np.shape
    if len(img_size) is not 3:
        print ('{} is not the right size!!!'.format(file_temp))
        return None,score_lst,xmin_lst,ymin_lst,xmax_lst,ymax_lst,num_no_target
    
    #predict
    datalist = []
    datalist = mm.predict(img_np)
    if len(datalist) < 1:
        print ('{} has not target!!!'.format(imgPath))
        num_no_target = num_no_target + 1
        #continue
        return img_np,score_lst,xmin_lst,ymin_lst,xmax_lst,ymax_lst,num_no_target
    
    #write xml
    if WRITE_XML:
        xmlfile = xml_lst[i].rsplit('.', 1)[0] + '.xml'
        xml.xml(output_xmlpath,xmlfile,datalist,img_size)
    
    #plot
    if PLOT:
        #re_image = os.path.join(output_image_temp,file_temp)                
        re_img_np = cv2.imread(imgPath)
        for j in xrange(len(datalist)):
            singledata = {}
            boxdict = {}
            singledata = datalist[j]
            boxdict = singledata['bbox']
            xmin = boxdict['xmin']
            ymin = boxdict['ymin']
            xmax = boxdict['xmax']
            ymax = boxdict['ymax']
            strscore = singledata['score']
            #print (type(strscore))
            #print (strscore)
            area = (ymax-ymin+1)*(xmax-xmin+1)
            if area<maxArea:
                score_lst.append(strscore)
                xmin_lst.append(xmin)
                ymin_lst.append(ymin)
                xmax_lst.append(xmax)
                ymax_lst.append(ymax)
                #print "src:",xmin,ymin,xmax,ymax
    return img_np,score_lst,xmin_lst,ymin_lst,xmax_lst,ymax_lst,num_no_target
    
def drawResult(img, score_lst,xmin_lst,ymin_lst,xmax_lst,ymax_lst,color=0,pixel=2):
    for i in range(len(score_lst)):
        xmin = xmin_lst[i]
        ymin = ymin_lst[i]
        xmax = xmax_lst[i]
        ymax = ymax_lst[i]
        strname = 'person'
        strscore = score_lst[i]
        font= cv2.FONT_HERSHEY_SIMPLEX
        
        if 0==color:
            cv2.rectangle(img, (xmin,ymin), (xmax,ymax),(0,0,255))
            #cv2.putText(img, strname + str(strscore) + '(' + str(xmax - xmin) + ',' + str(ymax - ymin) + ')', (xmin,ymin), font, 1,(0,0,255),2)
            cv2.putText(img, str(strscore) + '('+str(xmin)+','+ str(ymin)+','+str(xmax)+','+str(ymax)+')', (xmin,ymin), font, 0.5,(0,0,255),1)
        else:
            cv2.rectangle(img, (xmin-pixel,ymin-pixel), (xmax+pixel,ymax+pixel),(0,255,0))
            #cv2.putText(img, strname + str(strscore) + '(' + str(xmax - xmin) + ',' + str(ymax - ymin) + ')', (xmin,ymin), font, 1,(0,255,0),2)
            cv2.putText(img, str(strscore) + '('+str(xmin)+','+ str(ymin)+','+str(xmax)+','+str(ymax)+')', (xmin,ymin), font, 0.5,(0,255,0),1)
        #cv2.imwrite(savePath, img)
    return img

def calcIOU(xmin1,ymin1,xmax1,ymax1,xmin2,ymin2,xmax2,ymax2): #计算IOU
    xx1 = np.maximum(xmin1, xmin2)
    yy1 = np.maximum(ymin1, ymin2)
    xx2 = np.minimum(xmax1, xmax2)
    yy2 = np.minimum(ymax1, ymax2)
    w = np.maximum(0.0, xx2-xx1+1)
    h = np.maximum(0.0, yy2-yy1+1)
    inter = w * h        
    o = inter / ((xmax1-xmin1+1)*(ymax1-ymin1+1) + (xmax2-xmin2+1)*(ymax2-ymin2+1)- inter)
    return o
    
def calcUnion(xmin1,ymin1,xmax1,ymax1,xmin2,ymin2,xmax2,ymax2):  #计算2个矩形的外接矩形
    xx1 = np.minimum(xmin1, xmin2)
    yy1 = np.minimum(ymin1, ymin2)
    xx2 = np.maximum(xmax1, xmax2)
    yy2 = np.maximum(ymax1, ymax2)
    return xx1,yy1,xx2,yy2
    
def calcROIVale(img1,img2): #计算2幅图像差绝对值的均值
    shape1 = img1.shape
    row1 = shape1[0]
    col1 = shape1[1]
    
    shape2 = img2.shape
    row2 = shape2[0]
    col2 = shape2[1]
    
    if row1!=row2 or col1!=col2:
        return None
    else:
        img = cv2.absdiff(img1,img2)  
        s = np.sum(img)
        ave0 = s/(row1*col1)
        return ave0
 
def calcROIValeNew(img_all_abs, x1,y1,x2,y2): #计算时序图像均值或方差
    w = x2-x1+1
    h = y2-y1+1
    n = len(img_all_abs)
    if n<1:
        return None
    else:
        lst = []
        for i in range(n):
            rImg = img_all_abs[i][y1:y2,x1:x2]
            s = np.sum(rImg)
            ave0 = s/(w*h)
            lst.append(ave0)
        if PRINT:
            print lst
        
        if 1==n:  #2张图，计算均值
            return lst[0],lst 
        else:     #2张图以上，计算方差
            s = 0
            for i in range(n):
                s = s + lst[i]
            s = s/n
            
            var0 = 0
            for i in range(n):
                var0 = var0 + (lst[i]-s)*(lst[i]-s)
            var0 = var0/n
            return var0

def calcROIMaxAve(img_all_abs, x1,y1,x2,y2): #计算时序相邻图像差绝对值的均值的最大值
    w = x2-x1+1
    h = y2-y1+1
    n = len(img_all_abs)
    if n<1:
        return None
    else:
        lst = []
        for i in range(n):
            rImg = img_all_abs[i][y1:y2,x1:x2]
            s = np.sum(rImg)
            ave0 = s/(w*h)
            lst.append(ave0)
        if PRINT:
            print lst
            
        return max(lst)
        
def getImgAbs(img1,img2):
    shape1 = img1.shape
    row1 = shape1[0]
    col1 = shape1[1]
    
    shape2 = img2.shape
    row2 = shape2[0]
    col2 = shape2[1]
    
    if row1!=row2 or col1!=col2:
        return None
    else:
        img = cv2.absdiff(img1,img2)  
        return img
        
def getVar(lst):       
    m = 0.0
    v = 0.0
    
    for i in range(len(lst)):
        m = m+lst[i]
    m = m/len(lst)
    
    for i in range(len(lst)):
        v = v + (lst[i] - m)*(lst[i] - m)
    v = v/len(lst)
    return v
    
def filterBBox(img_all,score_lst_all,xmin_lst_all,ymin_lst_all,xmax_lst_all,ymax_lst_all, score_th,iou_th,th):
    x1_lst = []
    y1_lst = []
    x2_lst = []
    y2_lst = []
    s_lst = []
    imgIndex_lst = []
    for i in range(len(score_lst_all)): #image num
        for j in range(len(score_lst_all[i])): #bbox num
            x1_lst.append(xmin_lst_all[i][j])
            y1_lst.append(ymin_lst_all[i][j])
            x2_lst.append(xmax_lst_all[i][j])
            y2_lst.append(ymax_lst_all[i][j])
            s_lst.append(score_lst_all[i][j])
            imgIndex_lst.append(i)
          
    rows = len(x1_lst)
    iou_arr = np.zeros((rows,rows),dtype=int)
    iou_arr_temp = np.zeros((rows,rows),dtype=float)
    
    #计算相邻图像的差的绝对值
    img_all_abs = []
    if len(img_all)>1:
        for i in range(1,len(img_all)):
            img = getImgAbs(img_all[i-1],img_all[i])
            img_all_abs.append(img)
            
    lst_group = []
    for row in range(rows): # all bbox num
        for col in range(rows):  
            if row<col:  # top 
                xmin1 = x1_lst[row]
                ymin1 = y1_lst[row]
                xmax1 = x2_lst[row]
                ymax1 = y2_lst[row]
                
                xmin2 = x1_lst[col]
                ymin2 = y1_lst[col]
                xmax2 = x2_lst[col]
                ymax2 = y2_lst[col]
                o = calcIOU(xmin1,ymin1,xmax1,ymax1,xmin2,ymin2,xmax2,ymax2)
                iou_arr_temp[row][col] = o
                if o>iou_th and (imgIndex_lst[row]!=imgIndex_lst[col]):   ########### 0.9
                    iou_arr[row][col] = 1
                    lst_group.append([row,col])
    if PRINT:
        print "iou:"
        print iou_arr_temp                
        print "iou th:"
        print iou_arr                
    iou_arr_index = np.zeros((rows,1),dtype=int)
    if PRINT:
        print "lst_group: ", lst_group
    
    ################################################
    for row in range(rows): # all bbox num
        for col in range(rows):  
            if row<col:  # top 
                if 1==iou_arr[row][col] and (0==iou_arr_index[row][0] or 0==iou_arr_index[col][0]):
                    iou_arr_index[row][0] = row+1
                    iou_arr_index[col][0] = row+1
                    for i in range(rows):
                        if 1==iou_arr[i][col] or 1==iou_arr[row][i] or 1==iou_arr[i][row] or 1==iou_arr[col][i]:
                            iou_arr_index[i][0] =  row+1
    if PRINT:                           
        print "iou_arr_index:" ,iou_arr_index
    #################################################
    mv_arr_index = np.zeros((rows,1),dtype=int)
    for i in range(rows):
        if s_lst[i]>=score_th:
            continue
        
        if iou_arr_index[i][0]<1:  #处理时序图像中没有交集的bbox的索引
            bboxOK_index = i
            x1 = x1_lst[bboxOK_index]
            y1 = y1_lst[bboxOK_index]
            x2 = x2_lst[bboxOK_index]
            y2 = y2_lst[bboxOK_index]
            img = img_all[0][y1:y2,x1:x2]
            '''lst = []
            for j in range(1, len(img_all)):
                img_temp = img_all[j][y1:y2,x1:x2]
                ave0 = calcROIVale(img,img_temp)
                img = copy.deepcopy(img_temp)
                lst.append(ave0)'''
            if PRINT:
                print "IOU<th:"
                
            v = calcROIMaxAve(img_all_abs, x1,y1,x2,y2)
            #vv = calcROIValeNew(img_all_abs, x1,y1,x2,y2)
            if PRINT:            
                print "ave=", v
                #print "var=", vv
                
            if v<th:   #移除该误检
                mv_arr_index[i] = 1
                    
            '''
            v = calcROIValeNew(img_all_abs, x1,y1,x2,y2)  #
            if PRINT:            
                print v
            
            if v<th:   #移除该误检
                v1 = calcROIValeNew(img_all, x1,y1,x2,y2) #解决无-有-无的情况(122,121,方差很小)
                if PRINT:
                    print "src var:",v1
                if v1<th:
                    mv_arr_index[i] = 1 ''' 
                    
            '''if len(lst)>1:
                v = getVar(lst)
                print v
                if v<th:   #移除该误检
                    mv_arr_index[i] = 1  
            elif 1==len(lst):
                if lst[0]<th:   #移除该误检
                    mv_arr_index[i] = 1 '''
    if PRINT:                
        print "v<th and iou<th:", mv_arr_index
    
    #处理IOU>th的bbox
    lst_temp = []
    for ii in range(rows):
        if iou_arr_index[ii]>0:
            lst_temp.append(iou_arr_index[ii][0])
    lst_temp = list(set(lst_temp))
    lst_temp.sort()  #
    
    for j in range(len(lst_temp)):
        lst = []                #存放IOU>th的索引
        for ii in range(rows):
            if lst_temp[j]==iou_arr_index[ii][0]:
                lst.append(ii)
        if PRINT:
            print lst_temp[j], ":", lst   #4:[0,2,3,4](索引)
                
        if len(lst)<2:
            continue
        else:
            x11 = x1_lst[lst[0]]
            y11 = y1_lst[lst[0]]
            x12 = x2_lst[lst[0]]
            y12 = y2_lst[lst[0]]
            for iii in range(1,len(lst)):
                x21 = x1_lst[lst[iii]]
                y21 = y1_lst[lst[iii]]
                x22 = x2_lst[lst[iii]]
                y22 = y2_lst[lst[iii]]
                x11,y11,x12,y12 = calcUnion(x11,y11,x12,y12,x21,y21,x22,y22)
                
            '''img = img_all[0][y11:y12,x11:x12]
            lst1 = []  #存放相邻2张图同一个区域对应像素差的绝对值的均值
            for j in range(1, len(img_all)):
                img_temp = img_all[j][y11:y12,x11:x12]
                #print x11,y11,x12,y12
                ave0 = calcROIVale(img,img_temp) 
                img = copy.deepcopy(img_temp)
                lst1.append(ave0)'''
            if PRINT:
                print "IOU>th:"
            
            v = calcROIMaxAve(img_all_abs, x11,y11,x12,y12)
            #vv = calcROIValeNew(img_all_abs, x11,y11,x12,y12)
            if PRINT:            
                print "ave=", v
                #print "var=", vv
      
            if v<th:   #移除该误检
                isOK = 0
                for j1 in range(len(lst)):
                    if s_lst[lst[j1]]>=score_th:
                        isOK=1
                        continue
                        
                if not isOK: 
                    for j1 in range(len(lst)):  #一组bbox只要有一个的置信度>th，就不过滤
                            mv_arr_index[lst[j1]] = 1

            '''
            v = calcROIValeNew(img_all_abs, x11,y11,x12,y12)    
            if PRINT:
                print v
            
            if v<th:   #移除该误检
                isOK = 0
                for j1 in range(len(lst)):
                    if s_lst[lst[j1]]>score_th:
                        isOK=1
                        continue
                if not isOK: 
                    v1 = calcROIValeNew(img_all, x11,y11,x12,y12) #解决无-有-无的情况(122,121,方差很小)
                    if PRINT:
                        print "src var:",v1
                    if v1<th:
                        for j1 in range(len(lst)):  #一组bbox只要有一个的置信度>th，就不过滤
                            mv_arr_index[lst[j1]] = 1 '''
                            
            '''
            if len(lst1)>1: #大于等于3张图才计算方差
                v = getVar(lst1)
                print "var:", v
                
                if v<th:   #移除该误检
                    #for j1 in range(len(lst)):if s_lst[lst[j1]]<score_th:mv_arr_index[lst[j1]] = 1
                    isOK = 0
                    for j1 in range(len(lst)):
                        if s_lst[lst[j1]]>score_th:
                            isOK=1
                            continue
                    if not isOK:  
                        for j1 in range(len(lst)):  #一组bbox只要有一个的置信度>th，就不过滤
                            mv_arr_index[lst[j1]] = 1 
                            
            elif 1==len(lst1):  #2张图只计算对应像素差的绝对值的均值,用均值代替方差
                 if lst1[0]<th:   #移除该误检
                    #for j1 in range(len(lst)):if s_lst[lst[j1]]<score_th:mv_arr_index[lst[j1]] = 1
                    isOK=0
                    for j1 in range(len(lst)):
                        if s_lst[lst[j1]]>score_th:
                            isOK=1
                            continue
                    if not isOK:
                        for j1 in range(len(lst)):
                            mv_arr_index[lst[j1]] = 1'''
    if PRINT:            
        print "mv:",mv_arr_index
    
    x1_lst_res = []
    y1_lst_res = []
    x2_lst_res = []
    y2_lst_res = []
    s_lst_res = []
    n = 0
    for i in range(len(score_lst_all)): #image num ####################
        x1_lst1 = []
        y1_lst1 = []
        x2_lst1 = []
        y2_lst1 = []
        s_lst1 = []
        for j in range(len(score_lst_all[i])): #bbox num
            if 1!=mv_arr_index[n]:
                x1_lst1.append(xmin_lst_all[i][j])
                y1_lst1.append(ymin_lst_all[i][j])
                x2_lst1.append(xmax_lst_all[i][j])
                y2_lst1.append(ymax_lst_all[i][j])
                s_lst1.append(score_lst_all[i][j])
            n = n + 1
        x1_lst_res.append(x1_lst1)
        y1_lst_res.append(y1_lst1)
        x2_lst_res.append(x2_lst1)
        y2_lst_res.append(y2_lst1)
        s_lst_res.append(s_lst1)
        
    return s_lst_res,x1_lst_res,y1_lst_res,x2_lst_res,y2_lst_res          
  
def main(cfg_path,weights_path,input_imagespath,output_image,output_xmlpath,output_orig_image):
    #check path
    if not os.path.exists(input_imagespath):
        print ("input_imagespath is not exist!!!")
        return 
    if not os.path.exists(output_image):
        os.makedirs(output_image)
    if not os.path.exists(output_xmlpath):
        os.makedirs(output_xmlpath)
    #init
    mm = Model(cfg_path,weights_path)
    xml = Xml()
    
    maxArea = 9000*(1+0.3) #####################
    i=0
    num_no_target = 0
    files= os.listdir(input_imagespath)
    
    time_all = 0
    group_num = 0
    for file in files:
        if file.endswith('.jpg'):
            continue
        else:
            input_imagespath_new = os.path.join(input_imagespath,file)
            files_new = os.listdir(input_imagespath_new)
            score_lst_all = []
            i=0
            num = len(files_new)
            img_all = []
            score_lst_all = []
            xmin_lst_all = []
            ymin_lst_all = []
            xmax_lst_all = []
            ymax_lst_all = []
            
            if PRINT:
                print "group=", file
                
            savePath_lst_all = []
            for file_new in files_new:
                if file_new.endswith('.jpg'):
                    print (i,"/", num)
                    print file_new
                    imgPath = os.path.join(input_imagespath_new,file_new)
                    output_image_new = os.path.join(output_image,file)
                    xml_image_new = os.path.join(output_xmlpath,file)
                    if not os.path.exists(xml_image_new):
                        os.makedirs(xml_image_new)
                    '''if not os.path.exists(output_image_new):
                        os.makedirs(output_image_new)'''
                    #savePath = os.path.join(output_image_new,file_new)
                    savePath = os.path.join(output_image,file_new)
                    xmlPath = os.path.join(xml_image_new,file_new)
                    
                    savePath_lst_all.append(savePath)
                    img,score_lst,xmin_lst,ymin_lst,xmax_lst,ymax_lst,num_no_target = singlePredict(mm,imgPath, xmlPath,num_no_target, maxArea)
                    
                    for ii in range(len(xmin_lst)):
                        print xmin_lst[ii],ymin_lst[ii],xmax_lst[ii],ymax_lst[ii],score_lst[ii]
                        
                    if img is None:
                        continue
                    #print "11111:", score_lst
                    img_all.append(img)    #cv2.imread(imgPath))
                    score_lst_all.append(score_lst)
                    xmin_lst_all.append(xmin_lst)
                    ymin_lst_all.append(ymin_lst)
                    xmax_lst_all.append(xmax_lst)
                    ymax_lst_all.append(ymax_lst)
                    i = i+1
                    
            if PRINT:
                for ii in range(len(img_all)):
                    print "index:",ii
                    for jj in range(len(xmin_lst_all[ii])):
                        print xmin_lst_all[ii][jj],ymin_lst_all[ii][jj],xmax_lst_all[ii][jj],ymax_lst_all[ii][jj]
                    
            if len(img_all)>1:
                #filterBBox(img_all,score_lst_all,xmin_lst_all,ymin_lst_all,xmax_lst_all,ymax_lst_all, score_th,iou_th,th)
                start = time.time()
                score_lst_all_res,xmin_lst_all_res,ymin_lst_all_res,xmax_lst_all_res,ymax_lst_all_res=filterBBox(img_all,score_lst_all,xmin_lst_all,ymin_lst_all,xmax_lst_all,ymax_lst_all, 0.8,0.7,20)
                end = time.time()
                time_all = time_all + (end-start)
                group_num = group_num + 1
                
                for ii in range(len(img_all)): #画检测结果
                    #print len(xmin_lst_all_src[ii]),len(xmin_lst_all[ii])
                    img_temp = img_all[ii]
                    img_temp = drawResult(img_temp, score_lst_all[ii],xmin_lst_all[ii],ymin_lst_all[ii],xmax_lst_all[ii],ymax_lst_all[ii],color=0)#画原始检测结果
                    
                    img_temp = drawResult(img_temp, score_lst_all_res[ii],xmin_lst_all_res[ii],ymin_lst_all_res[ii],xmax_lst_all_res[ii],ymax_lst_all_res[ii],color=1) #画校正后的结果
                    cv2.imwrite(savePath_lst_all[ii], img_temp)
            else:
                for ii in range(len(img_all)): #画检测结果
                    img_temp = img_all[ii]
                    img_temp = drawResult(img_temp, score_lst_all[ii],xmin_lst_all[ii],ymin_lst_all[ii],xmax_lst_all[ii],ymax_lst_all[ii],color=1)
                    cv2.imwrite(savePath_lst_all[ii], img_temp)
    print "num_no_target=",num_no_target
    print time_all,group_num,time_all/group_num
if __name__ == '__main__':

    cfg_path = '/opt/ligang/Detectron/test_xml/model/retinanet_46_24999_infrared.yaml' #retinanet_71.yaml' 
    weights_path = '/opt/ligang/Detectron/test_xml/model/model_46_24999_infrared.pkl'  #'
    input_imagespath = '/opt/ligang/Detectron/test_xml/test1'
    replot_input_imagespath = '/opt/ligang/Detectron/test_xml/test1' #img_replot
    output_image     = '/opt/ligang/Detectron/test_xml/out1'
    output_xmlpath   = '/opt/ligang/Detectron/test_xml/xml1'
    output_orig_image     = '/opt/ligang/Detectron/test_xml/out_orig'
    main(cfg_path,weights_path,input_imagespath,output_image,output_xmlpath,output_orig_image)